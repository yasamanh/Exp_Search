{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> from gensim import corpora, models, similarities\n",
    ">>>\n",
    ">>> documents = [\"Human machine interface for lab abc computer applications\",\n",
    "                 \"The generation of random binary unordered trees\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = '/Users/ynh3/Data/AP/AP102'\n",
    "#f = '/Users/ynh3/Data/AP/AP101.txt'\n",
    "\n",
    "with open(f, 'r') as content_file:\n",
    "    content = content_file.read()\n",
    "\n",
    "documents = list(content.replace(\"\\n\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "documents = re.sub(\"[^\\w]\", \" \",  content).split()\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word.lower() for word in documents if word not in stoplist]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> stoplist = set('for a of the and to in'.split())\n",
    ">>> texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    ">>>          for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> from collections import defaultdict\n",
    ">>> frequency = defaultdict(int)\n",
    "\n",
    ">>> texts = [[token for token in text]\n",
    ">>>          for text in texts]\n",
    ">>>\n",
    ">>> from pprint import pprint   # pretty-printer\n",
    "#pprint(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(36 unique tokens: [u\"'\", u'-', u',', u'.', u'1']...)\n"
     ]
    }
   ],
   "source": [
    ">>> dictionary = corpora.Dictionary(texts)\n",
    ">>> dictionary.save('/tmp/deerwester.dict') # store the dictionary, for future reference\n",
    ">>> print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_cluster = 1\n",
    "# LSI computing\n",
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=n_cluster) # initialize an LSI transformation\n",
    "corpus_lsi = lsi[corpus_tfidf] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1.000*\"vietnam\" + 0.001*\"think\" + -0.001*\"force\" + -0.001*\"military\" + -0.001*\"society\" + 0.001*\"empty\" + -0.001*\"others\" + -0.001*\"anderson\" + -0.001*\"shaped\" + -0.001*\"film\"',\n",
       " u'-0.756*\"platoon\" + -0.607*\"who\" + -0.195*\"that\" + 0.149*\"said\" + 0.003*\"is\" + 0.002*\"screenplay\" + -0.002*\"publicity\" + 0.002*\"curious\" + 0.002*\"palm\" + 0.002*\"will\"',\n",
       " u'-0.862*\"that\" + 0.479*\"who\" + -0.165*\"platoon\" + -0.013*\"said\" + -0.003*\"robert\" + -0.003*\"referring\" + 0.002*\"film\" + -0.002*\"senior\" + 0.002*\"screen\" + -0.002*\"passed\"',\n",
       " u'-0.595*\"who\" + 0.492*\"platoon\" + -0.479*\"said\" + -0.418*\"that\" + 0.004*\"jacket\" + 0.003*\"new\" + 0.003*\"passage\" + 0.002*\"think\" + -0.002*\"professor\" + -0.002*\"friedman\"',\n",
       " u'-0.865*\"said\" + -0.400*\"platoon\" + 0.218*\"who\" + 0.211*\"that\" + -0.004*\"me\" + 0.004*\"think\" + 0.004*\"winning\" + 0.004*\"gerolmo\" + 0.003*\"cried\" + -0.003*\"oliver\"']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'-0.756*\"platoon\" + -0.607*\"who\" + -0.195*\"that\" + 0.149*\"said\" + 0.003*\"is\"'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.print_topic(1,topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSI model takes 0.00437808036804 seconds\n",
      "lsi is taking 0.000761985778809 seconds\n"
     ]
    }
   ],
   "source": [
    "    import time\n",
    "    import numpy as np\n",
    "    \n",
    "    n_cluster = 5\n",
    "    # LSI computing\n",
    "    t1=time.time()\n",
    "    lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=n_cluster) # initialize an LSI transformation\n",
    "    corpus_lsi = lsi[corpus_tfidf] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi\n",
    "    t2 = time.time()\n",
    "    print 'LSI model takes {} seconds'.format(t2 - t1)\n",
    "\n",
    "    # Creating LSI Label for each document\n",
    "    lsi_topic_labels=[]\n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    t1=time.time()\n",
    "    #topicmax is numpy.ndarray\n",
    "    for i,doc in enumerate(lsi[corpus_tfidf]):\n",
    "        a = np.array(doc)\n",
    "        absA= abs(a)\n",
    "        if (len(a)==0):\n",
    "            cluster_id=0\n",
    "            prob_value=0.0\n",
    "            j=j+1\n",
    "        else:\n",
    "            try:\n",
    "                topicmax = absA.argmax(axis=0)\n",
    "            except ValueError:\n",
    "                print \"ValueError at\"\n",
    "                print i\n",
    "                #print a\n",
    "            cluster_id = a[topicmax.item(1)][0]\n",
    "            prob_value = abs(a[topicmax.item(1)][1])\n",
    "\n",
    "        triple = i, cluster_id, prob_value\n",
    "        lsi_topic_labels.append(triple)\n",
    "        i=i+1\n",
    "    t2=time.time()\n",
    "    print 'lsi is taking {} seconds'.format(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-12e0f096060e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlsi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprob_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'+ '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtopics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: "
     ]
    }
   ],
   "source": [
    "    from operator import itemgetter\n",
    "    from collections import Counter\n",
    "    topics = []\n",
    "    for i in range(0, n_cluster):\n",
    "        l = lsi.print_topic(i,topn=5)\n",
    "        prob_list = [(abs(float(a[:5])),a[6:])  for a in (l.split('+ ')) if abs(float(a[:5])) > 0.3]\n",
    "        sorted(prob_list)\n",
    "        topics.append(prob_list)\n",
    "\n",
    "\n",
    "    ###MAKING READY FOR\n",
    "    cluster_topic_list = sorted(lsi_topic_labels,key=itemgetter(1,2), reverse=True)\n",
    "\n",
    "    cluster_list = sorted(lsi_topic_labels,key=lambda x: x[1])\n",
    "    counter = Counter(b for a,b,c in cluster_list)\n",
    "    counter_sort = counter.most_common(n_cluster)\n",
    "    cid_sort = [e[0] for e in counter_sort]\n",
    "\n",
    "    print 'length of lsi_topic_labels is {}'.format(len(lsi_topic_labels))\n",
    "    print 'length of cluster_list is {}'.format(len(cluster_list))\n",
    "    print 'length of counter_sort is {}'.format(len(counter_sort))\n",
    "    print 'n_cluster is {}'.format(n_cluster)\n",
    "    print 'cid_sort is {}'.format(len(cid_sort))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1.0, u'\"1960s\" ')]]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
