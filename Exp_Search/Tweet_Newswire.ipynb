{
 "metadata": {
  "name": "",
  "signature": "sha256:6848110fbcda352e59bae0296137516843f2ec11977cdb575964fb004ba3e6c8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from operator import itemgetter\n",
      "from collections import Counter\n",
      "import json\n",
      "import gzip\n",
      "from pprint import pprint\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "import pdb\n",
      "#file = '/Users/ynh3/Data/TweetsGZ/statuses.log.2015-04-03-00.gz'\n",
      "#o_f = '/Users/ynh3/Data/Intermediate/statuses.log.2015-03-31-05-re2'\n",
      "#f = gzip.open(i_f, 'rb')\n",
      "\n",
      "data = []\n",
      "\n",
      "setA = []\n",
      "setB = []\n",
      "setC = []\n",
      "setD = []\n",
      "\n",
      "setMention = []\n",
      "\n",
      "follower_count = 0\n",
      "re_follower_count = 0\n",
      "eng_count = 0\n",
      "mention_count = 0\n",
      "re_count = 0\n",
      "re_count_m = 0\n",
      "re_status = 0\n",
      "url_count = 0\n",
      "tweet_count = 0\n",
      "eng_tweet_count = 0\n",
      "follower_count_setA = 0\n",
      "\n",
      "bbc = []\n",
      "alj = []\n",
      "nytimes = []\n",
      "reuters = []\n",
      "yahoonews = []\n",
      "breakingnews = []\n",
      "npr = []\n",
      "cnn = []\n",
      "addele = []\n",
      "nasa = []\n",
      "food = []\n",
      "election = []\n",
      "politics = []\n",
      "entertainment = []\n",
      "wellness = []\n",
      "\n",
      "\n",
      "json_count = 0\n",
      "\n",
      "for file in os.listdir(\"/Users/ynh3/Data/TweetsGZ/\"):\n",
      "    if file.endswith(\".gz\"):\n",
      "        #print(file)\n",
      "        f=gzip.open(\"/Users/ynh3/Data/TweetsGZ/\"+file,'rb')\n",
      "\n",
      "        for l in f:\n",
      "            l = l.decode(\"ascii\",\"ignore\").encode(\"ascii\")\n",
      "            data = json.loads(l)\n",
      "            #pprint(data)\n",
      "\n",
      "            if \"lang\" in data:\n",
      "                if data[\"lang\"] == 'en':\n",
      "                    eng_count += 1\n",
      "\n",
      "                    if \"text\" in data:\n",
      "                        text = data[\"text\"].encode('utf-8').lower()\n",
      "                        \n",
      "                        if \"@BBCBreaking\" in data[\"text\"]:\n",
      "                            bbc.append(data[\"text\"])\n",
      "                        if \"@AJAM\" in data[\"text\"] or \"@AJEnglish\" in data[\"text\"]:\n",
      "                            alj.append(data[\"text\"])\n",
      "                        \n",
      "                        if \"@YahooNews\" in data[\"text\"]:\n",
      "                            yahoonews.append(data[\"text\"])\n",
      "                        if \"@Reuters\" in data[\"text\"]:\n",
      "                            reuters.append(data[\"text\"])\n",
      "                            \n",
      "                        if \"@NYtimes\" in data[\"text\"] or \"@NYT\" in data[\"text\"]:\n",
      "                            nytimes.append(data[\"text\"])\n",
      "                        if \"@cnn \" in data[\"text\"] or \"@CNN \" in data[\"text\"] or \"@cnnbrk\" in data[\"text\"]:\n",
      "                            cnn.append(data[\"text\"])\n",
      "                        if \"@npr\" in data[\"text\"] or \"@nprnews\" in data[\"text\"] or \"@NPR\" in data[\"text\"]:\n",
      "                            npr.append(data[\"text\"])\n",
      "                        if \"@BreakingNews\" in data[\"text\"]:\n",
      "                            breakingnews.append(data[\"text\"])    \n",
      "                        \n",
      "                        if \"@NASA\" in data[\"text\"]:\n",
      "                            nasa.append(data[\"text\"])\n",
      "                        \n",
      "                        if \"@OfficialAdele\" in text:\n",
      "                            addele.append(text)\n",
      "                            \n",
      "                        if \"@nytfood\" in text or \"@epicurious\" in text or \"@bonappetit\" in text:\n",
      "                            food.append(text)\n",
      "                            \n",
      "                        if \"@PreventionMag\" in text or \"@DrOzTheGoodLife\" in text or \"@EverydayHealth\" in text:\n",
      "                            wellnesss.append(text)\n",
      "                            \n",
      "                        if \"@CELEBUZZ\" in text or \"@accesshollywood\" in text or \"@OKMagazine\" in text:\n",
      "                            entertainment.append(text)\n",
      "                            \n",
      "                        if \"@realDonaldTrump\" in text or \"@tedcruz\" in text or \"@HillaryClinton\" in text or \"@BernieSanders\" in text:\n",
      "                            election.append(text)\n",
      "                        \n",
      "                        if \"@thehill\" in text or \"@politico\" in text or \"@postpolitics\" in text or \"@cspan\" in text:\n",
      "                            politics.append(text)\n",
      "                            \n",
      "            if \"text\" in data and \"created_at\" in data and \"id_str\" in data:\n",
      "                tweet_count += 1\n",
      "\n",
      "            json_count += 1\n",
      "        f.close()\n",
      "        print \"done with file: \", file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done with file:  statuses.log.2015-04-03-00.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-01.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-02.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-03.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-04.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-05.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-06.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-07.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-08.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-09.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-10.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-11.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-12.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-13.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-14.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-15.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-16.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-17.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-18.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-19.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-20.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-21.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-22.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-23.gz\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "newswire_sources = reuters + nytimes + yahoonews + alj + bbc + npr + cnn + breakingnews"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(entertainment)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 108,
       "text": [
        "15"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "entertainment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 109,
       "text": [
        "[\"will ferrell &amp; kristen wiig's secret lifetime movie 'a deadly adoption' http://t.co/krj4updaiz via @accesshollywood\",\n",
        " \"rt @accesshollywood: it's really happening! details on the #fullhouse spinoff! http://t.co/d3adxejaz5 http://t.co/dtnry8l2ya\",\n",
        " 'rt @accesshollywood: #winniethepooh goes live-action! the willy, nilly silly old bear is coming to theaters. http://t.co/ak8usdvdpc http://\\xe2\\x80\\xa6',\n",
        " 'rt @therock: top chick steph;) rt: @accesshollywood: the one &amp; only dwayne johnson, fresh off his hilarious #snl gig\\n#furious7 http://t.co/\\xe2\\x80\\xa6',\n",
        " 'rt @accesshollywood: the price was wrong! how did this @priceisright contestant accidentally win a new car?! http://t.co/tvftsd3l4e http://\\xe2\\x80\\xa6',\n",
        " 'rt @therock: top chick steph;) rt: @accesshollywood: the one &amp; only dwayne johnson, fresh off his hilarious #snl gig\\n#furious7 http://t.co/\\xe2\\x80\\xa6',\n",
        " 'rt @accesshollywood: the price was wrong! how did this @priceisright contestant accidentally win a new car?! http://t.co/tvftsd3l4e http://\\xe2\\x80\\xa6',\n",
        " 'rt @accesshollywood: the price was wrong! how did this @priceisright contestant accidentally win a new car?! http://t.co/tvftsd3l4e http://\\xe2\\x80\\xa6',\n",
        " \"rt @accesshollywood: if you haven't heard @george_ezra's music, your ears are in for a treat. we can't get enough! http://t.co/71zcsyxlk9 h\\xe2\\x80\\xa6\",\n",
        " 'rt @accesshollywood: the price was wrong! how did this @priceisright contestant accidentally win a new car?! http://t.co/tvftsd3l4e http://\\xe2\\x80\\xa6',\n",
        " \"rt @accesshollywood: .@therock lip syncs to @taylorswift13's 'shake it off' fast and furiously! http://t.co/vvqqkrasti #access http://t.co/\\xe2\\x80\\xa6\",\n",
        " 'rt @accesshollywood: the price was wrong! how did this @priceisright contestant accidentally win a new car?! http://t.co/tvftsd3l4e http://\\xe2\\x80\\xa6',\n",
        " \"@rtidwell730 @jolielash @caitrionambalfe @accesshollywood thank you, ma'am.\",\n",
        " \"rt @accesshollywood: can @nickiminaj's boobs heal the sick? bow down to her minajesty! http://t.co/d5zli4rraw #barbz #access http://t.co/8z\\xe2\\x80\\xa6\",\n",
        " 'rt @therock: top chick steph;) rt: @accesshollywood: the one &amp; only dwayne johnson, fresh off his hilarious #snl gig\\n#furious7 http://t.co/\\xe2\\x80\\xa6']"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fpath = \"/Users/ynh3/Documents/ExS/results/\"\n",
      "#i_f = open(fpath + 'newswire_sources_v2.txt', 'r')\n",
      "\n",
      "with open(fpath + 'newswire_sources_v2.txt', 'rb') as f:\n",
      "        newswire_sources = f.read().splitlines()\n",
      "\n",
      "f.close() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "newswire_sources[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "['RT @ReutersTech: IBM uncovers new, sophisticated bank transfer cyber scam http://t.co/sOn4BB2gXv',\n",
        " 'RT @ReutersOpinion: Nestl\\xc3\\xa9 called out for bottling, selling California water during drought: http://t.co/ftiqSchqsF http://t.co/yZiTyoRqvu',\n",
        " 'RT @ReutersBiz: Oil falls nearly 4 percent after tentative nuclear deal for Iran http://t.co/Ji26LEnjJt',\n",
        " 'RT @StopNuclearWar: U.S. jury awards $150 million for #Jeep fuel-tank fire death http://t.co/Yrv7EHbX71 via @Reuters #Chrysler',\n",
        " 'RT @RT_com: URGENT: US offer assistance to #Kenya to fight al Shabaab following #GarissaAttack - @Reuters http://t.co/QrQPgNCkMS http://t.c\\xe2\\x80\\xa6',\n",
        " 'RT @ReutersChalmers: Chinese influence in Cambodia grows with army school, aid http://t.co/XDm3FFOdeg',\n",
        " 'RT @ReutersBiz: Asian shares rise as U.S. jobs data awaited http://t.co/ROm0FEVy2C',\n",
        " 'RT @IBM: .@IBMsecurity uncovers new, sophisticated bank transfer cyber scam http://t.co/XYKNNgNk0f via @Reuters #DyreWolf http://t.co/9D5NE\\xe2\\x80\\xa6',\n",
        " 'RT @anniefofani: Oil falls nearly 4 percent after tentative nuclear deal for #Iran http://t.co/gjpSS1paMf via @Reuters',\n",
        " 'To stay or go? Indian nurses abroad weigh debts against danger http://t.co/RQKlPuZQvm via @Reuters #Yemen #Kerala']"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "print \"yes\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "yes\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fpath = \"/Users/ynh3/Documents/ExS/results/\"\n",
      "o_f = open(fpath + 'newswire_sources_v2.txt', 'w')\n",
      "for item in newswire_sources:\n",
      "  o_f.write(\"%s\\n\" % item.encode('utf-8'))\n",
      "o_f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eng_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "1385139"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "589109"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "re_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "1520"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "germanwings = [e for e in newswire_sources if \"germanwings\" in e.lower()]\n",
      "len(germanwings)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 122,
       "text": [
        "28"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###documents\n",
      "stoplist = set([line.replace(\"\\n\",\"\") for line in open('/Users/ynh3/Data/stopword-list.txt')])\n",
      "pun = [',', '-','.', ':', '(', ')', '--', ';', '...', 'can', 'say', 'says', 'will','may', 'must', 'us', 'via','a','the', 'rt', 'gg', 'gt', 'lt', 'la', 'de', 'te', 'lol', 'follow', 'followers', 'unfollow', 'unfollowers', 'unfollower', 'follower']\n",
      "#stoplist = set('for a of the and to in'.split())\n",
      "#texts = [[word for word in document.lower().split() if word not in stoplist and word not in pun]\n",
      "#        for document in setA]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "setB = [e.replace(\"\\r\",\" \") for e in setB]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## For later\n",
      "import CMUTweetTagger\n",
      "\n",
      "tagged_list = CMUTweetTagger.runtagger_parse(newswire_sources)\n",
      "len(tagged_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 82,
       "text": [
        "290"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## For later \n",
      "tweet_tokens=[]\n",
      "tweets_list = []\n",
      "#keep a list of actual tweets\n",
      "#tweets_entity_list=[]\n",
      "\n",
      "for y in tagged_list:\n",
      "    entity=[]\n",
      "    for e in y:\n",
      "        if e[1]=='^':\n",
      "            entity.append(e[0])\n",
      "    \n",
      "    if len(entity) > 0: \n",
      "        tweet_tokens.append(entity)\n",
      "        i = tagged_list.index(y)\n",
      "        tweets_list.append(newswire_sources[i])\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.tokenize import TweetTokenizer\n",
      "\n",
      "tknzr = TweetTokenizer()   \n",
      "tweet_count = 0\n",
      "tweet_tokens=[]\n",
      "tweet_list=[]\n",
      "i = 0\n",
      "\n",
      "for line in politics:\n",
      "\n",
      "    new_l = tknzr.tokenize(line)\n",
      "    lower_l = [e.lower() for e in new_l]\n",
      "    new_ll = [e for e in lower_l if e not in stoplist and e not in pun and len(e) > 2 and e.isalpha() and 'http' not in e and '@' not in e]\n",
      "\n",
      "    if len(new_ll) > 0:\n",
      "        tweet_tokens.append(new_ll)\n",
      "        tweet_count += 1\n",
      "        tweet_list.append(line)\n",
      "    i += 1\n",
      "\n",
      "print \"Done with tokenizations. tweets count: \" , tweet_count\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done with tokenizations. tweets count:  197\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweet_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 85,
       "text": [
        "197"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweet_list[:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 87,
       "text": [
        "['rt @thehill: hillary praises iran deal but warns \"the devil is always in the details\" http://t.co/r6aul4wjnt http://t.co/j61y0k9fr4',\n",
        " 'rt @politico: ted cruz is buying television ads in iowa and south carolina. http://t.co/w3nkh1ph2a',\n",
        " \"@thebrandonmorse @thehill ugh - episode 6 was as far as i got... couldn't watch anymore.\",\n",
        " 'boohoo poor state dept. \"@politico: state dept. cites \\'crushing\\' burden from foia requests. http://t.co/jwhpixxswk\"',\n",
        " \"rt @monicacrowley: i'm sure that went well.  rt @thehill obama phones netanyahu to discuss iran nuke deal: http://t.co/0ymusljxk3\",\n",
        " \"rt @kharyp: mark kirk blasts pence over 'religious freedom' law http://t.co/tjlzkeevkv via @politico #boycottindiana #rfra http://t.co/ghoh\\xe2\\x80\\xa6\",\n",
        " \"rt @politico: state dept. cites 'crushing' burden from foia requests. http://t.co/bjdidphatq\",\n",
        " 'sen. mark kirk likens iran deal to nazi appeasement, warns of nuclear conflict http://t.co/uxg760goce v\\xc3\\xada @politico',\n",
        " 'in rt @thehill: \"house of cards\" renewed for a fourth season: http://t.co/cvq2fnllyf http://t.co/hghzqbu55r',\n",
        " 'rt @thehill: \"house of cards\" renewed for a fourth season: http://t.co/4yxl5mdszu http://t.co/dqgy0enmul',\n",
        " 'rt @thehill: gop lawmakers rip iran nuclear deal: \"very dangerous proposal\" http://t.co/ykwil2iprg http://t.co/egmyyaprf1',\n",
        " 'rt @politico: trade bill timeline could push senate to act http://t.co/rmepzudwvj',\n",
        " 'i thought michele bachman was sold to disney with the other muppets@thehill',\n",
        " '@thehillierbloke not a warden about when u need em \\xf0\\x9f\\x98\\xa1\\xf0\\x9f\\x98\\xa1\\xf0\\x9f\\x98\\xa1\\xf0\\x9f\\x98\\xa1\\xf0\\x9f\\x98\\xa1',\n",
        " 'rt @tomkleeh: in rt @thehill: \"house of cards\" renewed for a fourth season: http://t.co/cvq2fnllyf http://t.co/hghzqbu55r',\n",
        " 'rt @thehill: democratic senator to return donations from indicted colleague menendez: http://t.co/qbijll35ex http://t.co/gnjwycwryx',\n",
        " 'rt @kimberly_canete: \\xe2\\x80\\x9c@thehill: hillary urges veto of arkansas religious freedom law: http://t.co/s55fhhvi7o http://t.co/ijkos1iozc\\xe2\\x80\\x9d',\n",
        " '@thehill will they donate it to the poor... you know, the christian thing to do?',\n",
        " 'cheesey\\nrt @thehill: over $200k raised for indiana pizzeria that refused to cater same-sex weddings: http://t.co/43kyshwckt',\n",
        " 'rt @politico: opinion: fox news is better at employing presidential candidates than electing them. http://t.co/egokxauzmb via @jackshafer']"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim import corpora, models\n",
      "\n",
      "dictionary = corpora.Dictionary(tweet_tokens)\n",
      "#dictionary.save('/tmp/AP890101.dict') # store the dictionary, for future reference\n",
      "print(dictionary)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(766 unique tokens: [u'writings', u'suicidal', u'remarkable', u'lack', u'focus']...)\n"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = [dictionary.doc2bow(t) for t in tweet_tokens]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus[:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 156,
       "text": [
        "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
        " [(8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)],\n",
        " [(15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1)]]"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf = models.TfidfModel(corpus)\n",
      "corpus_tfidf = tfidf[corpus]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_cluster = 5\n",
      "# LSI computing\n",
      "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=n_cluster) # initialize an LSI transformation\n",
      "corpus_lsi = lsi[corpus]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "j = 0\n",
      "lsi_topic_labels=[]\n",
      "for i,doc in enumerate(lsi[corpus_tfidf]):\n",
      "    a = np.array(doc)\n",
      "    absA= abs(a)\n",
      "    if (len(a)==0):\n",
      "        cluster_id=0\n",
      "        prob_value=0.0\n",
      "        j=j+1\n",
      "    else:\n",
      "        try:\n",
      "            topicmax = absA.argmax(axis=0)\n",
      "        except ValueError:\n",
      "            print \"ValueError at\"\n",
      "            print i\n",
      "            #print a\n",
      "        cluster_id = a[topicmax.item(1)][0]\n",
      "        prob_value = abs(a[topicmax.item(1)][1])\n",
      "\n",
      "    triple = i, cluster_id, prob_value\n",
      "    lsi_topic_labels.append(triple)\n",
      "    #print triple\n",
      "    l = lsi.print_topic(cluster_id,topn=10)\n",
      "    prob_list = [(abs(float(a[:5])),a[6:])  for a in (l.split('+ '))]\n",
      "    sorted(prob_list)\n",
      "    t_words = [w[1] for w in prob_list]\n",
      "    #if i < 10: print \"Tweet #\",i, \":\", \"topic:\",cluster_id, \",\",t_words\n",
      "    #else: break\n",
      "    i=i+1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topics = []\n",
      "for i in range(0, n_cluster):\n",
      "    l = lsi.print_topic(i,topn=5)\n",
      "    prob_list = [(abs(float(a[:5])),a[6:])  for a in (l.split('+ ')) if abs(float(a[:5])) > 0.3]\n",
      "    sorted(prob_list)\n",
      "    topics.append(prob_list)\n",
      "\n",
      "\n",
      "###MAKING READY FOR\n",
      "temp = sorted(lsi_topic_labels,key=itemgetter(1,2), reverse=True)\n",
      "cluster_topic_list = [e for e in temp if float(e[2]) > 0.2]\n",
      "leftovers_list = [tweet_list[e[0]] for e in temp if float(e[2]) <= 0.2]\n",
      "#Counter(a,b,c for a,b,c in lsi_topic_labels)\n",
      "\n",
      "cluster_list = sorted(cluster_topic_list,key=lambda x: x[1])\n",
      "counter = Counter(b for a,b,c in cluster_list)\n",
      "counter_sort = counter.most_common(n_cluster)\n",
      "cid_sort = [e[0] for e in counter_sort]\n",
      "\n",
      "print 'length of lsi_topic_labels is {}'.format(len(lsi_topic_labels))\n",
      "print 'length of cluster_list is {}'.format(len(cluster_list))\n",
      "print 'length of counter_sort is {}'.format(len(counter_sort))\n",
      "print 'n_cluster is {}'.format(n_cluster)\n",
      "print 'cid_sort is {}'.format(len(cid_sort))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of lsi_topic_labels is 197\n",
        "length of cluster_list is 55\n",
        "length of counter_sort is 5\n",
        "n_cluster is 5\n",
        "cid_sort is 5\n"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(leftovers_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 94,
       "text": [
        "142"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "leftovers_list[:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 95,
       "text": [
        "['rt @thehill: new bill would set term limits on members of congress: http://t.co/xik4et3avd http://t.co/gioqyrj6ne',\n",
        " 'rt @thehill: new bill would set term limits on members of congress: http://t.co/xik4et3avd http://t.co/gioqyrj6ne']"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('/Users/ynh3/Documents/ExS/results/politics_leftover_v3_5clusters.txt', 'wt') as myfile:\n",
      "    myfile.write('\\n'.join(leftovers_list))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counter_sort"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 97,
       "text": [
        "[(0.0, 21), (1.0, 12), (2.0, 9), (3.0, 7), (4.0, 6)]"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#cluster_topic_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counter_sort"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "[(0.0, 48), (1.0, 32), (4.0, 31), (2.0, 24), (3.0, 10)]"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cid_sort"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "[0.0, 1.0, 4.0, 2.0, 3.0]"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l = lsi.print_topic(0,topn=5)\n",
      "l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 99,
       "text": [
        "u'-0.534*\"iran\" + -0.529*\"deal\" + -0.413*\"nuclear\" + -0.214*\"obama\" + -0.145*\"gop\"'"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cluster_topic_list[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "[(0, 19.0, 0.73547713680220062),\n",
        " (20, 19.0, 0.73547713680220062),\n",
        " (55, 19.0, 0.73547713680220062),\n",
        " (7, 19.0, 0.70937099820029259),\n",
        " (64, 19.0, 0.57905186085136873),\n",
        " (444, 19.0, 0.29305233315383439),\n",
        " (449, 19.0, 0.29305233315383439),\n",
        " (136, 19.0, 0.29048454763036752),\n",
        " (137, 19.0, 0.29048454763036752),\n",
        " (482, 19.0, 0.28572404449452049)]"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l = lsi.print_topic(17,topn=10)\n",
      "prob_list = [(abs(float(a[:5])),a[6:])  for a in (l.split('+ ')) if abs(float(a[:5])) > 0.3]\n",
      "a = l.split('+ ')[0]\n",
      "a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "u'0.278*\"just\" '"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi.show_topics()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 100,
       "text": [
        "[u'-0.534*\"iran\" + -0.529*\"deal\" + -0.413*\"nuclear\" + -0.214*\"obama\" + -0.145*\"gop\" + -0.118*\"democrats\" + -0.116*\"top\" + -0.116*\"skepticism\" + -0.116*\"great\" + -0.096*\"hillary\"',\n",
        " u'-0.603*\"obama\" + -0.309*\"power\" + -0.309*\"train\" + -0.309*\"veterans\" + -0.242*\"wants\" + -0.233*\"workers\" + -0.233*\"industry\" + -0.233*\"solar\" + 0.113*\"iran\" + -0.106*\"state\"',\n",
        " u'-0.487*\"hillary\" + -0.451*\"clinton\" + -0.337*\"signed\" + -0.288*\"brooklyn\" + -0.264*\"lease\" + -0.210*\"source\" + -0.210*\"headquarters\" + -0.169*\"campaign\" + 0.134*\"nuclear\" + -0.115*\"announcement\"',\n",
        " u'0.515*\"state\" + 0.258*\"paul\" + 0.258*\"view\" + 0.258*\"strong\" + 0.258*\"insiders\" + 0.258*\"early\" + 0.258*\"contender\" + 0.192*\"illustration\" + 0.192*\"getty\" + 0.192*\"caucus\"',\n",
        " u'-0.469*\"house\" + -0.433*\"season\" + -0.433*\"cards\" + -0.433*\"fourth\" + -0.433*\"renewed\" + 0.048*\"nuclear\" + -0.043*\"hillary\" + -0.038*\"clinton\" + -0.037*\"white\" + -0.031*\"law\"']"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = lsi.show_topics()\n",
      "with open('/Users/ynh3/Documents/ExS/results/politics_topics_v3_5clusters.txt', 'wt') as myfile:\n",
      "    myfile.write('\\n\\n'.join(t))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pdb\n",
      "\n",
      "#def myfunction():\n",
      "fpath = \"/Users/ynh3/Documents/ExS/results/\"\n",
      "output_file = open(fpath + 'politics_sources_v3_LSI_5clusters.txt', 'w')\n",
      "\n",
      "data_list=[]\n",
      "data = {}\n",
      "count=0\n",
      "i=0\n",
      "\n",
      "for i in range(0, len(cid_sort)):\n",
      "    sublist = [e for e in cluster_topic_list if e[1] == cid_sort[i]]\n",
      "    #if i == 1:\n",
      "    #print \"index\", t_index\n",
      "    t_index = int(cid_sort[i])\n",
      "    #count = int(counter_sort[i][1])\n",
      "    #start = sum([e[1] for e in counter_sort[:i]])\n",
      "    #sublist = cluster_topic_list[start:count]\n",
      "    #pdb.set_trace()\n",
      "    #if i < 2: print start, count, len(sublist)\n",
      "\n",
      "    topic = lsi.print_topic(t_index,topn=10)\n",
      "    #topic = topics[t_index]\n",
      "    #string = [x[1] for x in topic]\n",
      "    string = ' '.join(topic)\n",
      "    #print topic\n",
      "    if string == \"\":\n",
      "        print i\n",
      "        print cid_sort[i], t_index\n",
      "        print topic\n",
      "        #print sublist\n",
      "\n",
      "        break\n",
      "    #topic_str = string\n",
      "    \n",
      "    l = [tweet_list[ss[0]] for ss in sublist if float(ss[2]) > 0.2]\n",
      "    \n",
      "    output_file.write(\"\\n\\n\")\n",
      "    output_file.write('Cluster # %d' %t_index + '-----------------------\\n')\n",
      "    output_file.write('Total items # %d' %len(l) + '-----------------------\\n\\n')\n",
      "    output_file.write(topic+'\\n')\n",
      "\n",
      "    \n",
      " \n",
      "    #pdb.set_trace()\n",
      "   #for j in range(0,len(sublist)):\n",
      "    #    data = {}\n",
      "    #    index = sublist[j][0]\n",
      "    #    if (index >= len(tweet_list)):\n",
      "    #        print index, i, j\n",
      "    #        break\n",
      "    #    tweet_str = tweet_list[index]\n",
      "    #    tweet = ' '.join(tweet_str)\n",
      "    #    count=count+1\n",
      "         #output_file.write(tweet_str+'\\n')\n",
      "    \n",
      "    \n",
      "    \n",
      "    print('Cluster # %d' %t_index + '-----------------------\\n')\n",
      "    print('Total items # %d' %len(l) + '-----------------------\\n\\n')\n",
      "    print(topic+'\\n')\n",
      "    print(\"\\n\".join(l))\n",
      "    #pdb.set_trace()\n",
      "\n",
      "    output_file.write(\"\\n\".join(l))\n",
      "\n",
      "\n",
      "        #count_str = str(count)\n",
      "\n",
      "#print(\"Total number of tweets is {}\".format(count))\n",
      "output_file.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Cluster # 0-----------------------\n",
        "\n",
        "Total items # 21-----------------------\n",
        "\n",
        "\n",
        "-0.534*\"iran\" + -0.529*\"deal\" + -0.413*\"nuclear\" + -0.214*\"obama\" + -0.145*\"gop\" + -0.118*\"democrats\" + -0.116*\"top\" + -0.116*\"skepticism\" + -0.116*\"great\" + -0.096*\"hillary\"\n",
        "\n",
        "rt @thehill: top democrats have \"great skepticism\" over iran nuclear deal: http://t.co/5mwj5x9qnd http://t.co/y75qywoggc\n",
        "rt @thehill: top democrats have \"great skepticism\" over iran nuclear deal: http://t.co/5mwj5x9qnd http://t.co/y75qywoggc\n",
        "rt @thehill: top democrats express \"great skepticism\" over iran nuclear deal: http://t.co/v5goy753y8 http://t.co/ouwzbwkb51\n",
        "rt @thehill: top democrats express \"great skepticism\" over iran nuclear deal: http://t.co/ajjycux4va http://t.co/cqkc4neocd\n",
        "rt @thehill: gop denounces proposed iran nuclear deal: http://t.co/xbr22ggww4 http://t.co/nvm3h6uwsp\n",
        "rt @thehill: gop denounces proposed iran nuclear deal: http://t.co/xbr22ggww4 http://t.co/nvm3h6uwsp\n",
        "rt @thehill: gop lawmakers rip iran nuclear deal: \"very dangerous proposal\" http://t.co/ykwil2iprg http://t.co/egmyyaprf1\n",
        "rt @thehill: gop lawmakers rip iran nuclear deal: \"very dangerous proposal\" http://t.co/ykwil2iprg http://t.co/egmyyaprf1\n",
        "rt @monicacrowley: i'm sure that went well.  rt @thehill obama phones netanyahu to discuss iran nuke deal: http://t.co/0ymusljxk3\n",
        "rt @monicacrowley: i'm sure that went well.  rt @thehill obama phones netanyahu to discuss iran nuke deal: http://t.co/aa64vuifvu\n",
        "rt @thehill: nuclear deal has iranians snapping obama selfies: http://t.co/aalxzgp0y1 http://t.co/5h57kyil7h\n",
        "rt @thehill: nuclear deal has iranians snapping obama selfies: http://t.co/aalxzgp0y1 http://t.co/5h57kyil7h\n",
        "rt @calvarezaranyos: not according to thomas jefferson. rt @thehill: sen. bob corker: obama must bring iran nuclear deal to congress http:/\u2026\n",
        "rt @politico: potential gop presidential contenders accused the white house of striking a seriously flawed nuclear deal with iran http://t.\u2026\n",
        "rt @thehill: white house says response to proposed iran nuke deal is \"reassuring\" http://t.co/huolouolgh http://t.co/5qxvgfkyla\n",
        "sen. mark kirk likens iran deal to nazi appeasement, warns of nuclear conflict http://t.co/uxg760goce v\u00eda @politico\n",
        "the gray areas in the iran deal via @politico  http://t.co/vvduqhcmp5\n",
        "rt @thehill: hillary praises iran deal but warns \"the devil is always in the details\" http://t.co/r6aul4wjnt http://t.co/j61y0k9fr4\n",
        "@politico\n",
        "netanyahu 03: if iraq isn't invaded, israel's survival at risk\n",
        "\n",
        "#netanyahu 15: if iran deal is signed, israel's survival at risk\n",
        "rt @thehill: iranian president hassan rouhani vows to honor nuclear deal: http://t.co/2qqhu4pcem http://t.co/8h55k2rabb\n",
        "hillary clinton's secret iran man http://t.co/b3lqxxpaf3 via @politico\n",
        "Cluster # 1-----------------------\n",
        "\n",
        "Total items # 12-----------------------\n",
        "\n",
        "\n",
        "-0.603*\"obama\" + -0.309*\"power\" + -0.309*\"train\" + -0.309*\"veterans\" + -0.242*\"wants\" + -0.233*\"workers\" + -0.233*\"industry\" + -0.233*\"solar\" + 0.113*\"iran\" + -0.106*\"state\"\n",
        "\n",
        "rt @thehill: obama wants to train 75,000 workers \u2014 many of them veterans \u2014 for the solar power industry: http://t.co/1lciklqhah http://t.co\u2026\n",
        "rt @thehill: obama wants to train 75,000 workers \u2014 many of them veterans \u2014 for the solar power industry: http://t.co/1lciklqhah http://t.co\u2026\n",
        "rt @thehill: obama wants to train 75,000 workers \u2014 many of them veterans \u2014 for the solar power industry: http://t.co/1lciklqhah http://t.co\u2026\n",
        "rt @younglibdaniel: rt @thehill: obama wants to train 75,000 workers \u2014 many of them veterans \u2014 for the solar power industry: http://t.co/sp\u2026\n",
        "rt @sierraclub: obama pushes to train veterans for #solar power: http://t.co/vei1ufy5xj (via @thehill)\n",
        "rt @solar_org: obama pushes to train veterans for #solar power: (via @thehill) #obama http://t.co/st3ezbilb2\n",
        "rt @thehill: obama is now one state away from visiting all 50 as president: http://t.co/lp71jml0cw http://t.co/s4jpmaxikf\n",
        "rt @thehill: obama is now one state away from visiting all 50 as president: http://t.co/lp71jml0cw http://t.co/s4jpmaxikf\n",
        "@masonicprince32 @cspanwj obama has  over 20 trillion in debt makes terrorists look like girlie men compared to that devil obama.\n",
        "rt @thehill: can you guess the one state obama has yet to visit as president?: http://t.co/cxrjkgoohj http://t.co/1uzl8vvvtl\n",
        "obama was right, congress was wrong, again. @politico  http://t.co/22sh7sbiof\n",
        "rt @thehill: as president, barack obama has now visited 49 states: http://t.co/2w2mlqqj2z http://t.co/tfhojunefw\n",
        "Cluster # 2-----------------------\n",
        "\n",
        "Total items # 9-----------------------\n",
        "\n",
        "\n",
        "-0.487*\"hillary\" + -0.451*\"clinton\" + -0.337*\"signed\" + -0.288*\"brooklyn\" + -0.264*\"lease\" + -0.210*\"source\" + -0.210*\"headquarters\" + -0.169*\"campaign\" + 0.134*\"nuclear\" + -0.115*\"announcement\"\n",
        "\n",
        "rt @politico: source: lease signed for hillary clinton headquarters in brooklyn http://t.co/9airkpwion\n",
        "rt @politico: source: lease signed for hillary clinton headquarters in brooklyn http://t.co/9airkpwion\n",
        "source: lease signed for hillary clinton headquarters in brooklyn http://t.co/hblncq5ppy via @politico welcome to the neighborhood\n",
        "rt @politico2016: it\u2019s official: hillary clinton has signed the deal for a campaign hq. next up: the april announcement. http://t.co/cka7eg\u2026\n",
        "rt @politico2016: it\u2019s official: hillary clinton has signed the deal for a campaign hq. next up: the april announcement. http://t.co/cka7eg\u2026\n",
        "rt @thehill: hillary clinton signs lease for 2016 campaign hq in brooklyn: report http://t.co/yepxoleyci http://t.co/kby7iiscdc\n",
        "hillary clinton's brooklyn http://t.co/cbmitddsdf via @politico #nhpolitics #uniteblue http://t.co/cga7oz3ola\n",
        "rt @politico2016: jake sullivan, who helped bring about the iran nuclear talks, may have to help hillary clinton defend them in 2016. http:\u2026\n",
        "rt @kimberly_canete: \u201c@thehill: hillary urges veto of arkansas religious freedom law: http://t.co/s55fhhvi7o http://t.co/ijkos1iozc\u201d\n",
        "Cluster # 3-----------------------\n",
        "\n",
        "Total items # 7-----------------------\n",
        "\n",
        "\n",
        "0.515*\"state\" + 0.258*\"paul\" + 0.258*\"view\" + 0.258*\"strong\" + 0.258*\"insiders\" + 0.258*\"early\" + 0.258*\"contender\" + 0.192*\"illustration\" + 0.192*\"getty\" + 0.192*\"caucus\"\n",
        "\n",
        "rt @politico: politico caucus: insiders view rand paul as strong early state contender http://t.co/q5z44ofgdv | illustration/getty http://t\u2026\n",
        "rt @politico: politico caucus: insiders view rand paul as strong early state contender http://t.co/q5z44ofgdv | illustration/getty http://t\u2026\n",
        "insiders view paul as strong early state contender http://t.co/wmn2w1f9vc via @politico\n",
        "boohoo poor state dept. \"@politico: state dept. cites 'crushing' burden from foia requests. http://t.co/jwhpixxswk\"\n",
        "rt @politico: state dept. cites 'crushing' burden from foia requests. http://t.co/bjdidphatq\n",
        "@thehill the state of reality?\n",
        "rt @judicialwatch: .@statedept cites 'crushing' burden from #foia http://t.co/kfdyb6zqrr via @politico\n",
        "Cluster # 4-----------------------\n",
        "\n",
        "Total items # 6-----------------------\n",
        "\n",
        "\n",
        "-0.469*\"house\" + -0.433*\"season\" + -0.433*\"cards\" + -0.433*\"fourth\" + -0.433*\"renewed\" + 0.048*\"nuclear\" + -0.043*\"hillary\" + -0.038*\"clinton\" + -0.037*\"white\" + -0.031*\"law\"\n",
        "\n",
        "in rt @thehill: \"house of cards\" renewed for a fourth season: http://t.co/cvq2fnllyf http://t.co/hghzqbu55r\n",
        "rt @thehill: \"house of cards\" renewed for a fourth season: http://t.co/4yxl5mdszu http://t.co/dqgy0enmul\n",
        "rt @tomkleeh: in rt @thehill: \"house of cards\" renewed for a fourth season: http://t.co/cvq2fnllyf http://t.co/hghzqbu55r\n",
        "rt @thehill: \"house of cards\" renewed for a fourth season: http://t.co/4yxl5mdszu http://t.co/dqgy0enmul\n",
        "rt @thehill: \"house of cards\" renewed for a fourth season: http://t.co/i7ycxuald2 http://t.co/0h3oymjktz\n",
        "rt @thehill: \"house of cards\" renewed for a fourth season: http://t.co/4yxl5mdszu http://t.co/dqgy0enmul\n",
        "Total number of tweets is 0\n"
       ]
      }
     ],
     "prompt_number": 102
    }
   ],
   "metadata": {}
  }
 ]
}