{
 "metadata": {
  "name": "",
  "signature": "sha256:076d2ab5e7f076952a1715bcf7930af6b554446afea7987ee1ced91e4d1731c4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from operator import itemgetter\n",
      "from collections import Counter\n",
      "import json\n",
      "import gzip\n",
      "from pprint import pprint\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "#file = '/Users/ynh3/Data/TweetsGZ/statuses.log.2015-04-03-00.gz'\n",
      "#o_f = '/Users/ynh3/Data/Intermediate/statuses.log.2015-03-31-05-re2'\n",
      "#f = gzip.open(i_f, 'rb')\n",
      "\n",
      "data = []\n",
      "\n",
      "setA = []\n",
      "setB = []\n",
      "setC = []\n",
      "setD = []\n",
      "\n",
      "setMention = []\n",
      "\n",
      "follower_count = 0\n",
      "re_follower_count = 0\n",
      "eng_count = 0\n",
      "mention_count = 0\n",
      "re_count = 0\n",
      "re_count_m = 0\n",
      "re_status = 0\n",
      "url_count = 0\n",
      "tweet_count = 0\n",
      "eng_tweet_count = 0\n",
      "follower_count_setA = 0\n",
      "\n",
      "bbc = []\n",
      "alj = []\n",
      "nytimes = []\n",
      "reuters = []\n",
      "yahoonews = []\n",
      "breakingnews = []\n",
      "npr = []\n",
      "cnn = []\n",
      "addele = []\n",
      "nasa = []\n",
      "json_count = 0\n",
      "\n",
      "for file in os.listdir(\"/Users/ynh3/Data/TweetsGZ/\"):\n",
      "    if file.endswith(\".gz\"):\n",
      "        #print(file)\n",
      "        f=gzip.open(\"/Users/ynh3/Data/TweetsGZ/\"+file,'rb')\n",
      "\n",
      "        for l in f:\n",
      "            l = l.decode(\"ascii\",\"ignore\").encode(\"ascii\")\n",
      "            data = json.loads(l)\n",
      "            #pprint(data)\n",
      "\n",
      "            if \"lang\" in data:\n",
      "                if data[\"lang\"] == 'en':\n",
      "                    eng_count += 1\n",
      "\n",
      "                    if \"text\" in data:\n",
      "                        if \"@BBCBreaking\" in data[\"text\"]:\n",
      "                            bbc.append(data[\"text\"])\n",
      "                        if \"@AJAM\" in data[\"text\"] or \"@AJEnglish\" in data[\"text\"]:\n",
      "                            alj.append(data[\"text\"])\n",
      "                        \n",
      "                        if \"@YahooNews\" in data[\"text\"]:\n",
      "                            yahoonews.append(data[\"text\"])\n",
      "                        if \"@Reuters\" in data[\"text\"]:\n",
      "                            reuters.append(data[\"text\"])\n",
      "                            \n",
      "                        if \"@NYtimes\" in data[\"text\"] or \"@NYT\" in data[\"text\"]:\n",
      "                            nytimes.append(data[\"text\"])\n",
      "                        if \"@cnn \" in data[\"text\"] or \"@CNN \" in data[\"text\"] or \"@cnnbrk\" in data[\"text\"]:\n",
      "                            cnn.append(data[\"text\"])\n",
      "                        if \"@npr\" in data[\"text\"] or \"@nprnews\" in data[\"text\"] or \"@NPR\" in data[\"text\"]:\n",
      "                            npr.append(data[\"text\"])\n",
      "                        if \"@BreakingNews\" in data[\"text\"]:\n",
      "                            breakingnews.append(data[\"text\"])    \n",
      "                        if \"@NASA\" in data[\"text\"]:\n",
      "                            nasa.append(data[\"text\"])\n",
      "                        if \"@OfficialAdele\" in data[\"text\"]:\n",
      "                            addele.append(data[\"text\"])\n",
      "                            \n",
      "\n",
      "                            \n",
      "            if \"text\" in data and \"created_at\" in data and \"id_str\" in data:\n",
      "                tweet_count += 1\n",
      "\n",
      "            json_count += 1\n",
      "            #if json_count >1000:\n",
      "            #    break\n",
      "        f.close()\n",
      "        print \"done with file: \", file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done with file:  statuses.log.2015-04-03-00.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-01.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-02.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-03.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-04.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-05.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-06.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-07.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-08.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-09.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-10.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-11.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-12.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-13.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-14.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-15.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-16.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-17.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-18.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-19.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-20.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-21.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-22.gz\n",
        "done with file: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " statuses.log.2015-04-03-23.gz\n"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "newswire_sources = reuters + nytimes + yahoonews + alj + bbc + npr + cnn + breakingnews"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(breakingnews)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 117,
       "text": [
        "17"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(newswire_sources)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 234,
       "text": [
        "875"
       ]
      }
     ],
     "prompt_number": 234
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fpath = \"/Users/ynh3/Documents/ExS/results/\"\n",
      "#i_f = open(fpath + 'newswire_sources_v2.txt', 'r')\n",
      "\n",
      "with open(fpath + 'newswire_sources_v2.txt', 'rb') as f:\n",
      "        newswire_sources = f.read().splitlines()\n",
      "\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "newswire_sources[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "['RT @ReutersTech: IBM uncovers new, sophisticated bank transfer cyber scam http://t.co/sOn4BB2gXv',\n",
        " 'RT @ReutersOpinion: Nestl\\xc3\\xa9 called out for bottling, selling California water during drought: http://t.co/ftiqSchqsF http://t.co/yZiTyoRqvu',\n",
        " 'RT @ReutersBiz: Oil falls nearly 4 percent after tentative nuclear deal for Iran http://t.co/Ji26LEnjJt',\n",
        " 'RT @StopNuclearWar: U.S. jury awards $150 million for #Jeep fuel-tank fire death http://t.co/Yrv7EHbX71 via @Reuters #Chrysler',\n",
        " 'RT @RT_com: URGENT: US offer assistance to #Kenya to fight al Shabaab following #GarissaAttack - @Reuters http://t.co/QrQPgNCkMS http://t.c\\xe2\\x80\\xa6',\n",
        " 'RT @ReutersChalmers: Chinese influence in Cambodia grows with army school, aid http://t.co/XDm3FFOdeg',\n",
        " 'RT @ReutersBiz: Asian shares rise as U.S. jobs data awaited http://t.co/ROm0FEVy2C',\n",
        " 'RT @IBM: .@IBMsecurity uncovers new, sophisticated bank transfer cyber scam http://t.co/XYKNNgNk0f via @Reuters #DyreWolf http://t.co/9D5NE\\xe2\\x80\\xa6',\n",
        " 'RT @anniefofani: Oil falls nearly 4 percent after tentative nuclear deal for #Iran http://t.co/gjpSS1paMf via @Reuters',\n",
        " 'To stay or go? Indian nurses abroad weigh debts against danger http://t.co/RQKlPuZQvm via @Reuters #Yemen #Kerala']"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "print \"yes\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "yes\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fpath = \"/Users/ynh3/Documents/ExS/results/\"\n",
      "o_f = open(fpath + 'newswire_sources_v2.txt', 'w')\n",
      "for item in newswire_sources:\n",
      "  o_f.write(\"%s\\n\" % item.encode('utf-8'))\n",
      "o_f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eng_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "1385139"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "589109"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "re_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "1520"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "germanwings = [e for e in newswire_sources if \"germanwings\" in e.lower()]\n",
      "len(germanwings)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 122,
       "text": [
        "28"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###documents\n",
      "stoplist = set([line.replace(\"\\n\",\"\") for line in open('/Users/ynh3/Data/stopword-list.txt')])\n",
      "pun = [',', '-','.', ':', '(', ')', '--', ';', '...', 'can', 'say', 'will','may', 'must', 'us', 'via','a','the', 'rt', 'gg', 'gt', 'lt', 'la', 'de', 'te', 'lol', 'follow', 'followers', 'unfollow', 'unfollowers', 'unfollower', 'follower']\n",
      "#stoplist = set('for a of the and to in'.split())\n",
      "#texts = [[word for word in document.lower().split() if word not in stoplist and word not in pun]\n",
      "#        for document in setA]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "setB = [e.replace(\"\\r\",\" \") for e in setB]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## For later\n",
      "import CMUTweetTagger\n",
      "\n",
      "tagged_list = CMUTweetTagger.runtagger_parse(newswire_sources)\n",
      "len(tagged_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 82,
       "text": [
        "290"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## For later \n",
      "tweet_tokens=[]\n",
      "tweets_list = []\n",
      "#keep a list of actual tweets\n",
      "#tweets_entity_list=[]\n",
      "\n",
      "for y in tagged_list:\n",
      "    entity=[]\n",
      "    for e in y:\n",
      "        if e[1]=='^':\n",
      "            entity.append(e[0])\n",
      "    \n",
      "    if len(entity) > 0: \n",
      "        tweet_tokens.append(entity)\n",
      "        i = tagged_list.index(y)\n",
      "        tweets_list.append(newswire_sources[i])\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.tokenize import TweetTokenizer\n",
      "\n",
      "tknzr = TweetTokenizer()   \n",
      "tweet_count = 0\n",
      "tweet_tokens=[]\n",
      "tweet_list=[]\n",
      "i = 0\n",
      "\n",
      "for line in newswire_sources:\n",
      "\n",
      "    new_l = tknzr.tokenize(line)\n",
      "    lower_l = [e.lower() for e in new_l]\n",
      "    new_ll = [e for e in lower_l if e not in stoplist and e not in pun and len(e) > 2 and e.isalpha() and 'http' not in e and '@' not in e]\n",
      "\n",
      "    if len(new_ll) > 0:\n",
      "        tweet_tokens.append(new_ll)\n",
      "        tweet_count += 1\n",
      "        tweet_list.append(line)\n",
      "    i += 1\n",
      "\n",
      "print \"Done with tokenizations. tweets count: \" , tweet_count\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done with tokenizations. tweets count:  826\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweet_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 232,
       "text": [
        "826"
       ]
      }
     ],
     "prompt_number": 232
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweet_list[:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 171,
       "text": [
        "['RT @ReutersTech: IBM uncovers new, sophisticated bank transfer cyber scam http://t.co/sOn4BB2gXv',\n",
        " 'RT @ReutersOpinion: Nestl\\xc3\\xa9 called out for bottling, selling California water during drought: http://t.co/ftiqSchqsF http://t.co/yZiTyoRqvu',\n",
        " 'RT @ReutersBiz: Oil falls nearly 4 percent after tentative nuclear deal for Iran http://t.co/Ji26LEnjJt',\n",
        " 'RT @StopNuclearWar: U.S. jury awards $150 million for #Jeep fuel-tank fire death http://t.co/Yrv7EHbX71 via @Reuters #Chrysler',\n",
        " 'RT @RT_com: URGENT: US offer assistance to #Kenya to fight al Shabaab following #GarissaAttack - @Reuters http://t.co/QrQPgNCkMS http://t.c\\xe2\\x80\\xa6',\n",
        " 'RT @ReutersChalmers: Chinese influence in Cambodia grows with army school, aid http://t.co/XDm3FFOdeg',\n",
        " 'RT @ReutersBiz: Asian shares rise as U.S. jobs data awaited http://t.co/ROm0FEVy2C',\n",
        " 'RT @IBM: .@IBMsecurity uncovers new, sophisticated bank transfer cyber scam http://t.co/XYKNNgNk0f via @Reuters #DyreWolf http://t.co/9D5NE\\xe2\\x80\\xa6',\n",
        " 'RT @anniefofani: Oil falls nearly 4 percent after tentative nuclear deal for #Iran http://t.co/gjpSS1paMf via @Reuters',\n",
        " 'To stay or go? Indian nurses abroad weigh debts against danger http://t.co/RQKlPuZQvm via @Reuters #Yemen #Kerala',\n",
        " 'RT @Reuters: Al Shabaab kills at least 147 at Kenyan university; siege ends http://t.co/fD3bNehHdK',\n",
        " \"RT @mizfolia: @chevymo @Reuters I know Monica, I read they sorted out the Christians from the Muslims. I've been thinking about that all da\\xe2\\x80\\xa6\",\n",
        " '@Cnnbrk @Foxnews Iran And World Powers Agree On Framework For Nuclear Deal - Huffington Post http://t.co/myppk3VfJu @Reuters @AP #Iran',\n",
        " 'RT @ReutersUS: Kansas will allow concealed carry of guns without a permit http://t.co/2wwgTCb1Xx',\n",
        " 'MT @Reuters: #Israel dismisses celebrations of #Iran nuclear framework deal as \"detached from wretched reality\" http://t.co/P2gjsGc3Ju',\n",
        " 'RT @Terence_Writing: @Reuters u know Reuters, news of high water to brink of flooding in Kashmir was news on twitter a few days ago cc @The\\xe2\\x80\\xa6',\n",
        " 'RT @Reuters: Al Shabaab kills at least 147 at Kenyan university; siege ends http://t.co/fD3bNehHdK',\n",
        " \"RT @Reuters: China's services sector expands in March, job growth at 10-month low: survey http://t.co/hUJsedb12J\",\n",
        " 'RT @Reuters: Al Shabaab kills at least 147 at Kenyan university; siege ends http://t.co/fD3bNehHdK',\n",
        " \"RT @ReutersPolitics: Why tensions with Elizabeth Warren could loom over Hillary Clinton's presidential campaign: http://t.co/oyzuZ99hAA htt\\xe2\\x80\\xa6\"]"
       ]
      }
     ],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim import corpora, models\n",
      "\n",
      "dictionary = corpora.Dictionary(tweet_tokens)\n",
      "#dictionary.save('/tmp/AP890101.dict') # store the dictionary, for future reference\n",
      "print(dictionary)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(2092 unique tokens: [u'rev', u'facilities', u'protest', u'woods', u'asian']...)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/ynh3/clustering/algo_test/lib/python2.7/site-packages/gensim-0.10.2-py2.7-macosx-10.9-intel.egg/gensim/__init__.py:10: UserWarning: Module gensim was already imported from /Users/ynh3/clustering/algo_test/lib/python2.7/site-packages/gensim-0.10.2-py2.7-macosx-10.9-intel.egg/gensim/__init__.pyc, but /Users/ynh3/clustering/algo_test/bin is being added to sys.path\n",
        "  __version__ = __import__('pkg_resources').get_distribution('gensim').version\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = [dictionary.doc2bow(t) for t in tweet_tokens]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary.token2id()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "'dict' object is not callable",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-155-5ae168cbebb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus[:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 156,
       "text": [
        "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
        " [(8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)],\n",
        " [(15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1)]]"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf = models.TfidfModel(corpus)\n",
      "corpus_tfidf = tfidf[corpus]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_cluster = 5\n",
      "# LSI computing\n",
      "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=n_cluster) # initialize an LSI transformation\n",
      "corpus_lsi = lsi[corpus]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi.print_topic(9,topn=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "''"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi_topic_labels[:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "[(0, 19.0, 0.73547713680220062), (1, 3.0, 0.15039933934001642)]"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "j = 0\n",
      "lsi_topic_labels=[]\n",
      "for i,doc in enumerate(lsi[corpus_tfidf]):\n",
      "    a = np.array(doc)\n",
      "    absA= abs(a)\n",
      "    if (len(a)==0):\n",
      "        cluster_id=0\n",
      "        prob_value=0.0\n",
      "        j=j+1\n",
      "    else:\n",
      "        try:\n",
      "            topicmax = absA.argmax(axis=0)\n",
      "        except ValueError:\n",
      "            print \"ValueError at\"\n",
      "            print i\n",
      "            #print a\n",
      "        cluster_id = a[topicmax.item(1)][0]\n",
      "        prob_value = abs(a[topicmax.item(1)][1])\n",
      "\n",
      "    triple = i, cluster_id, prob_value\n",
      "    lsi_topic_labels.append(triple)\n",
      "    #print triple\n",
      "    l = lsi.print_topic(cluster_id,topn=10)\n",
      "    prob_list = [(abs(float(a[:5])),a[6:])  for a in (l.split('+ '))]\n",
      "    sorted(prob_list)\n",
      "    t_words = [w[1] for w in prob_list]\n",
      "    #if i < 10: print \"Tweet #\",i, \":\", \"topic:\",cluster_id, \",\",t_words\n",
      "    #else: break\n",
      "    i=i+1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topics = []\n",
      "for i in range(0, n_cluster):\n",
      "    l = lsi.print_topic(i,topn=5)\n",
      "    prob_list = [(abs(float(a[:5])),a[6:])  for a in (l.split('+ ')) if abs(float(a[:5])) > 0.3]\n",
      "    sorted(prob_list)\n",
      "    topics.append(prob_list)\n",
      "\n",
      "\n",
      "###MAKING READY FOR\n",
      "cluster_topic_list = sorted(lsi_topic_labels,key=itemgetter(1,2), reverse=True)\n",
      "#Counter(a,b,c for a,b,c in lsi_topic_labels)\n",
      "\n",
      "cluster_list = sorted(lsi_topic_labels,key=lambda x: x[1])\n",
      "counter = Counter(b for a,b,c in cluster_list)\n",
      "counter_sort = counter.most_common(n_cluster)\n",
      "cid_sort = [e[0] for e in counter_sort]\n",
      "\n",
      "print 'length of lsi_topic_labels is {}'.format(len(lsi_topic_labels))\n",
      "print 'length of cluster_list is {}'.format(len(cluster_list))\n",
      "print 'length of counter_sort is {}'.format(len(counter_sort))\n",
      "print 'n_cluster is {}'.format(n_cluster)\n",
      "print 'cid_sort is {}'.format(len(cid_sort))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of lsi_topic_labels is 826\n",
        "length of cluster_list is 826\n",
        "length of counter_sort is 5\n",
        "n_cluster is 5\n",
        "cid_sort is 5\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi.print_topic(18)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "u'0.359*\"primitive\" + 0.359*\"using\" + 0.359*\"knives\" + 0.359*\"modern\" + 0.359*\"surgeons\" + 0.342*\"forceps\" + 0.342*\"scissors\" + 0.342*\"scalpel\" + 0.016*\"flight\" + 0.010*\"germanwings\"'"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweet_list[594]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "'RT @cnni: Can animals predict earthquakes? They can, new study hints: http://t.co/F4NKGF1Q2t http://t.co/XNfkxDH93O'"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#cluster_topic_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counter_sort"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "[(17.0, 81),\n",
        " (13.0, 74),\n",
        " (19.0, 69),\n",
        " (7.0, 53),\n",
        " (9.0, 52),\n",
        " (0.0, 49),\n",
        " (11.0, 48),\n",
        " (14.0, 47),\n",
        " (2.0, 44),\n",
        " (10.0, 42),\n",
        " (3.0, 41),\n",
        " (12.0, 33),\n",
        " (15.0, 29),\n",
        " (16.0, 29),\n",
        " (6.0, 27),\n",
        " (1.0, 26),\n",
        " (18.0, 23),\n",
        " (5.0, 20),\n",
        " (8.0, 20),\n",
        " (4.0, 19)]"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cid_sort"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "[17.0,\n",
        " 13.0,\n",
        " 19.0,\n",
        " 7.0,\n",
        " 9.0,\n",
        " 0.0,\n",
        " 11.0,\n",
        " 14.0,\n",
        " 2.0,\n",
        " 10.0,\n",
        " 3.0,\n",
        " 12.0,\n",
        " 15.0,\n",
        " 16.0,\n",
        " 6.0,\n",
        " 1.0,\n",
        " 18.0,\n",
        " 5.0,\n",
        " 8.0,\n",
        " 4.0]"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l = lsi.print_topic(17,topn=5)\n",
      "l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "u'0.427*\"flight\" + 0.282*\"germanwings\" + -0.280*\"confirms\" + -0.235*\"take\" + 0.205*\"descent\"'"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cluster_topic_list[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "[(0, 19.0, 0.73547713680220062),\n",
        " (20, 19.0, 0.73547713680220062),\n",
        " (55, 19.0, 0.73547713680220062),\n",
        " (7, 19.0, 0.70937099820029259),\n",
        " (64, 19.0, 0.57905186085136873),\n",
        " (444, 19.0, 0.29305233315383439),\n",
        " (449, 19.0, 0.29305233315383439),\n",
        " (136, 19.0, 0.29048454763036752),\n",
        " (137, 19.0, 0.29048454763036752),\n",
        " (482, 19.0, 0.28572404449452049)]"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l = lsi.print_topic(17,topn=10)\n",
      "prob_list = [(abs(float(a[:5])),a[6:])  for a in (l.split('+ ')) if abs(float(a[:5])) > 0.3]\n",
      "a = l.split('+ ')[0]\n",
      "a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "u'0.278*\"just\" '"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi.show_topics()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "[u'-0.522*\"deal\" + -0.438*\"nuclear\" + -0.307*\"president\" + -0.272*\"rouhani\" + -0.241*\"iran\" + -0.228*\"iranian\" + -0.227*\"stick\" + -0.224*\"promises\" + -0.212*\"hassan\" + -0.125*\"pending\"',\n",
        " u'-0.424*\"black\" + -0.418*\"box\" + -0.411*\"confirms\" + -0.386*\"flight\" + -0.338*\"investigators\" + -0.300*\"acted\" + -0.300*\"deliberately\" + -0.061*\"increased\" + -0.061*\"germanwings\" + -0.061*\"speed\"',\n",
        " u'-0.460*\"university\" + -0.400*\"people\" + -0.378*\"arrested\" + -0.335*\"massacre\" + -0.307*\"garissa\" + -0.306*\"college\" + -0.297*\"connection\" + -0.144*\"attack\" + -0.112*\"kenya\" + -0.097*\"killed\"',\n",
        " u'0.356*\"days\" + 0.343*\"man\" + 0.311*\"water\" + 0.309*\"rescued\" + 0.309*\"sea\" + 0.282*\"catching\" + 0.282*\"fish\" + 0.282*\"survived\" + 0.260*\"hands\" + 0.256*\"drinking\"',\n",
        " u'0.412*\"today\" + 0.327*\"luther\" + 0.288*\"last\" + 0.279*\"day\" + 0.269*\"martin\" + 0.266*\"speech\" + 0.266*\"mountaintop\" + 0.266*\"famed\" + 0.266*\"gave\" + 0.204*\"king\"',\n",
        " u'-0.322*\"who\" + -0.318*\"plot\" + -0.297*\"charged\" + -0.293*\"being\" + -0.290*\"ties\" + -0.289*\"prison\" + -0.289*\"murder\" + -0.286*\"released\" + -0.285*\"florida\" + -0.281*\"kkk\"',\n",
        " u'0.425*\"day\" + 0.269*\"nigeria\" + 0.228*\"reporting\" + 0.225*\"know\" + 0.203*\"attack\" + 0.202*\"need\" + 0.199*\"syria\" + 0.199*\"call\" + 0.196*\"kenya\" + 0.196*\"talk\"',\n",
        " u'0.535*\"iran\" + 0.282*\"deal\" + -0.265*\"stick\" + -0.259*\"iranian\" + -0.257*\"promises\" + -0.248*\"hassan\" + -0.214*\"rouhani\" + 0.197*\"obama\" + -0.193*\"president\" + -0.134*\"pending\"',\n",
        " u'-0.702*\"love\" + -0.335*\"japan\" + -0.309*\"bicycle\" + -0.309*\"cycling\" + -0.309*\"route\" + -0.309*\"spectacular\" + -0.051*\"respect\" + -0.026*\"works\" + -0.025*\"apply\" + -0.025*\"intrinsic\"',\n",
        " u'0.373*\"attack\" + 0.357*\"kenya\" + -0.231*\"nigeria\" + -0.222*\"know\" + -0.207*\"arrested\" + -0.191*\"need\" + -0.187*\"call\" + -0.187*\"syria\" + -0.184*\"talk\" + 0.180*\"dead\"']"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"hello\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 224
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pdb\n",
      "\n",
      "#def myfunction():\n",
      "fpath = \"/Users/ynh3/Documents/ExS/results/\"\n",
      "output_file = open(fpath + 'newswire_sources_v2_LSI_5clusters.txt', 'w')\n",
      "\n",
      "data_list=[]\n",
      "data = {}\n",
      "count=0\n",
      "i=0\n",
      "\n",
      "for i in range(0, len(cid_sort)):\n",
      "    sublist = [e for e in cluster_topic_list if e[1] == cid_sort[i]]\n",
      "    #if i == 1:\n",
      "    #print \"index\", t_index\n",
      "    t_index = int(cid_sort[i])\n",
      "    #count = int(counter_sort[i][1])\n",
      "    #start = sum([e[1] for e in counter_sort[:i]])\n",
      "    #sublist = cluster_topic_list[start:count]\n",
      "    #pdb.set_trace()\n",
      "    #if i < 2: print start, count, len(sublist)\n",
      "\n",
      "    topic = lsi.print_topic(t_index,topn=10)\n",
      "    #topic = topics[t_index]\n",
      "    #string = [x[1] for x in topic]\n",
      "    string = ' '.join(topic)\n",
      "    #print topic\n",
      "    if string == \"\":\n",
      "        print i\n",
      "        print cid_sort[i], t_index\n",
      "        print topic\n",
      "        #print sublist\n",
      "\n",
      "        break\n",
      "    topic_str = string\n",
      "    output_file.write(\"\\n\\n\")\n",
      "    output_file.write('Cluster # %d' %t_index + '-----------------------\\n')\n",
      "    output_file.write('Total items # %d' %len(l) + '-----------------------\\n\\n')\n",
      "    output_file.write(topic+'\\n')\n",
      "\n",
      "    \n",
      " \n",
      "    #pdb.set_trace()\n",
      "   #for j in range(0,len(sublist)):\n",
      "    #    data = {}\n",
      "    #    index = sublist[j][0]\n",
      "    #    if (index >= len(tweet_list)):\n",
      "    #        print index, i, j\n",
      "    #        break\n",
      "    #    tweet_str = tweet_list[index]\n",
      "    #    tweet = ' '.join(tweet_str)\n",
      "    #    count=count+1\n",
      "         #output_file.write(tweet_str+'\\n')\n",
      "    \n",
      "    l = [tweet_list[ss[0]] for ss in sublist if float(ss[2]) > 0.2]\n",
      "    \n",
      "    print('Cluster # %d' %t_index + '-----------------------\\n')\n",
      "    print('Total items # %d' %len(l) + '-----------------------\\n\\n')\n",
      "    print(topic+'\\n')\n",
      "    print(\"\\n\".join(l))\n",
      "    #pdb.set_trace()\n",
      "\n",
      "    output_file.write(\"\\n\".join(l))\n",
      "\n",
      "\n",
      "        #count_str = str(count)\n",
      "\n",
      "print(\"Total number of tweets is {}\".format(count))\n",
      "output_file.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Cluster # 2-----------------------\n",
        "\n",
        "Total items # 24-----------------------\n",
        "\n",
        "\n",
        "0.460*\"university\" + 0.400*\"people\" + 0.378*\"arrested\" + 0.335*\"massacre\" + 0.307*\"garissa\" + 0.306*\"college\" + 0.296*\"connection\" + 0.144*\"attack\" + 0.111*\"kenya\" + 0.097*\"killed\"\n",
        "\n",
        "RT @cnnbrk: 5 arrested in connection with massacre of 147 people at Kenya's Garissa University College. http://t.co/qRsepSebKR\n",
        "RT @cnnbrk: 5 arrested in connection with massacre of 147 people at Kenya's Garissa University College. http://t.co/qRsepSebKR\n",
        "RT @cnnbrk: 5 arrested in connection with massacre of 147 people at Kenya's Garissa University College. http://t.co/qRsepSebKR\n",
        "RT @cnnbrk: 5 arrested in connection with massacre of 147 people at Kenya's Garissa University College. http://t.co/qRsepSebKR\n",
        "RT @cnnbrk: 5 arrested in connection with massacre of 147 people at Kenya's Garissa University College. http://t.co/qRsepSebKR\n",
        "RT @cnnbrk: 5 arrested in connection with massacre of 147 people at Kenya's Garissa University College. http://t.co/qRsepSebKR\n",
        "RT @cnnbrk: 5 arrested in connection with massacre of 147 people at Kenya's Garissa University College. http://t.co/qRsepSebKR\n",
        "RT @cnnbrk: 5 arrested in connection with massacre of 147 people at Kenya's Garissa University College. http://t.co/qRsepSebKR\n",
        "RT @cnnbrk: 5 arrested in connection with massacre of 147 people at Kenya's Garissa University College. http://t.co/qRsepSebKR\n",
        "RT @cnnbrk: 5 arrested in connection with massacre of 147 people at Kenya's Garissa University College. http://t.co/qRsepSebKR\n",
        "RT @cnnbrk: 5 arrested in connection with massacre of 147 people at Kenya's Garissa University College. http://t.co/qRsepSebKR\n",
        "RT @cnnbrk: 5 arrested in connection with massacre of 147 people at Kenya's Garissa University College. http://t.co/qRsepSebKR\n",
        "RT @cnnbrk: 5 arrested in connection with massacre of 147 people at Kenya's Garissa University College. http://t.co/qRsepSebKR\n",
        "RT @cnnbrk: Kenyan agency confirms via Twitter that 147 people were killed in today's attack at Garissa University College. http://t.co/o6k\u2026\n",
        "RT @cnni: 147 killed in university massacre, deadliest terror attack in Kenya since U.S. Embassy bombed in 1998 http://t.co/ca4lefmpWT #Gar\u2026\n",
        "RT @cnni: 147 killed in university massacre, deadliest terror attack in Kenya since U.S. Embassy bombed in 1998 http://t.co/ca4lefmpWT #Gar\u2026\n",
        "RT @cnni: 147 killed in university massacre, deadliest terror attack in Kenya since U.S. Embassy bombed in 1998 http://t.co/ca4lefmpWT #Gar\u2026\n",
        "RT @cnni: 147 killed in university massacre, deadliest terror attack in Kenya since U.S. Embassy bombed in 1998 http://t.co/ca4lefmpWT #Gar\u2026\n",
        "RT @CNNSitRoom: 147 people killed in university attack; most were shot in the back of the head: http://t.co/qfq4LI3DGf #GarissaAttack http:\u2026\n",
        "RT @KenyanTraffic: \u201c@cnnbrk: Kenya offers reward for man wanted in connection with deadly university attack. http://t.co/hXynFGVAmg http://\u2026\n",
        "RT @BreakingNews: Coach Shaka Smart leaving Virginia Commonwealth University for job at University of Texas, sources say - @CSNNCAA http://\u2026\n",
        "RT @BreakingNews: Coach Shaka Smart leaving Virginia Commonwealth University for job at University of Texas, sources say - @CSNNCAA http://\u2026\n",
        "RT @BBCBreaking: Six people have been arrested in Dover on suspicion of Syria-related terrorism offences, West Midlands Police say http://t\u2026\n",
        "RT @BBCBreaking: Six people have been arrested in Dover on suspicion of Syria-related terrorism offences, West Midlands Police say http://t\u2026\n",
        "Cluster # 4-----------------------\n",
        "\n",
        "Total items # 31-----------------------\n",
        "\n",
        "\n",
        "-0.412*\"today\" + -0.327*\"luther\" + -0.287*\"last\" + -0.278*\"day\" + -0.270*\"martin\" + -0.266*\"mountaintop\" + -0.266*\"gave\" + -0.266*\"speech\" + -0.266*\"famed\" + -0.204*\"king\"\n",
        "\n",
        "RT @YahooNews: Dr. Martin Luther King Jr. gave his famed Mountaintop speech today in 1968 http://t.co/OJyaw0VcFO Was also his last http://t\u2026\n",
        "RT @YahooNews: Dr. Martin Luther King Jr. gave his famed Mountaintop speech today in 1968 http://t.co/OJyaw0VcFO Was also his last http://t\u2026\n",
        "RT @YahooNews: Dr. Martin Luther King Jr. gave his famed Mountaintop speech today in 1968 http://t.co/OJyaw0VcFO Was also his last http://t\u2026\n",
        "RT @YahooNews: Dr. Martin Luther King Jr. gave his famed Mountaintop speech today in 1968 http://t.co/OJyaw0VcFO Was also his last http://t\u2026\n",
        "RT @YahooNews: Dr. Martin Luther King Jr. gave his famed Mountaintop speech today in 1968 http://t.co/OJyaw0VcFO Was also his last http://t\u2026\n",
        "RT @YahooNews: Dr. Martin Luther King Jr. gave his famed Mountaintop speech today in 1968 http://t.co/OJyaw0VcFO Was also his last http://t\u2026\n",
        "RT @YahooNews: Dr. Martin Luther King Jr. gave his famed Mountaintop speech today in 1968 http://t.co/OJyaw0VcFO Was also his last http://t\u2026\n",
        "RT @YahooNews: Martin Luther Luther gave his famed Mountaintop speech today in 1968 http://t.co/Ib3Z99clKW It was also his last http://t.co\u2026\n",
        "RT @YahooNews: Martin Luther Luther gave his famed Mountaintop speech today in 1968 http://t.co/Ib3Z99clKW It was also his last http://t.co\u2026\n",
        "RT @_marystcloud: SPREAD IT! Idc if you go to USC or not we're going to make her day today! #USCGamecocks @gracentilton @cnn http://t.co/2r\u2026\n",
        "RT @_marystcloud: SPREAD IT! Idc if you go to USC or not we're going to make her day today! #USCGamecocks @gracentilton @cnn http://t.co/2r\u2026\n",
        "RT @_marystcloud: SPREAD IT! Idc if you go to USC or not we're going to make her day today! #USCGamecocks @gracentilton @cnn http://t.co/2r\u2026\n",
        "RT @_marystcloud: SPREAD IT! Idc if you go to USC or not we're going to make her day today! #USCGamecocks @gracentilton @cnn http://t.co/2r\u2026\n",
        "RT @_marystcloud: SPREAD IT! Idc if you go to USC or not we're going to make her day today! #USCGamecocks @gracentilton @cnn http://t.co/2r\u2026\n",
        "RT @xoxoDana: RT @_marystcloud: SPREAD IT! Idc if you go to USC or not we're going to make her day today! #USC @gracentilton @cnn http://t.\u2026\n",
        "RT @_marystcloud: SPREAD IT! Idc if you go to USC or not we're going to make her day today! #USCGamecocks @gracentilton @cnn http://t.co/2r\u2026\n",
        "RT @_marystcloud: SPREAD IT! Idc if you go to USC or not we're going to make her day today! #USCGamecocks @gracentilton @cnn http://t.co/2r\u2026\n",
        "RT @_marystcloud: SPREAD IT! Idc if you go to USC or not we're going to make her day today! #USCGamecocks @gracentilton @cnn http://t.co/2r\u2026\n",
        "RT @elnathan: You know @CNN, we really need to talk about this. One day you will be reporting in Syria and call it Nigeria. http://t.co/Jh3\u2026\n",
        "RT @elnathan: You know @CNN, we really need to talk about this. One day you will be reporting in Syria and call it Nigeria. http://t.co/Jh3\u2026\n",
        "RT @elnathan: You know @CNN, we really need to talk about this. One day you will be reporting in Syria and call it Nigeria. http://t.co/Jh3\u2026\n",
        "RT @elnathan: You know @CNN, we really need to talk about this. One day you will be reporting in Syria and call it Nigeria. http://t.co/Jh3\u2026\n",
        "RT @elnathan: You know @CNN, we really need to talk about this. One day you will be reporting in Syria and call it Nigeria. http://t.co/Jh3\u2026\n",
        "RT @elnathan: You know @CNN, we really need to talk about this. One day you will be reporting in Syria and call it Nigeria. http://t.co/Jh3\u2026\n",
        "RT @elnathan: You know @CNN, we really need to talk about this. One day you will be reporting in Syria and call it Nigeria. http://t.co/Jh3\u2026\n",
        "RT @elnathan: You know @CNN, we really need to talk about this. One day you will be reporting in Syria and call it Nigeria. http://t.co/Jh3\u2026\n",
        "RT @cnnbrk: A day after attack on Kenya school that left 147 dead, many victims\u2019 bodies remain, waiting to be transported off. http://t.co/\u2026\n",
        "RT @cnnbrk: A day after attack on Kenya school that left 147 dead, many victims\u2019 bodies remain, waiting to be transported off. http://t.co/\u2026\n",
        "RT @cnnbrk: A day after attack on Kenya school that left 147 dead, many victims\u2019 bodies remain, waiting to be transported off. http://t.co/\u2026\n",
        "RT @cnnbrk: A day after attack on Kenya school that left 147 dead, many victims\u2019 bodies remain, waiting to be transported off. http://t.co/\u2026\n",
        "RT @cnnbrk: A day after attack on Kenya school that left 147 dead, many victims\u2019 bodies remain, waiting to be transported off. http://t.co/\u2026\n",
        "Cluster # 0-----------------------\n",
        "\n",
        "Total items # 52-----------------------\n",
        "\n",
        "\n",
        "-0.522*\"deal\" + -0.438*\"nuclear\" + -0.307*\"president\" + -0.272*\"rouhani\" + -0.241*\"iran\" + -0.228*\"iranian\" + -0.227*\"stick\" + -0.224*\"promises\" + -0.212*\"hassan\" + -0.125*\"pending\"\n",
        "\n",
        "RT @cnnbrk: Iranian President Hassan Rouhani: \"We will stick to our promises\" in pending nuclear deal if others do the same. http://t.co/Y0\u2026\n",
        "RT @cnnbrk: Iranian President Hassan Rouhani: \"We will stick to our promises\" in pending nuclear deal if others do the same. http://t.co/Y0\u2026\n",
        "RT @cnnbrk: Iranian President Hassan Rouhani: \"We will stick to our promises\" in pending nuclear deal if others do the same. http://t.co/Y0\u2026\n",
        "RT @cnnbrk: Iranian President Hassan Rouhani: \"We will stick to our promises\" in pending nuclear deal if others do the same. http://t.co/Y0\u2026\n",
        "RT @cnnbrk: Iranian President Hassan Rouhani: \"We will stick to our promises\" in pending nuclear deal if others do the same. http://t.co/Y0\u2026\n",
        "RT @cnnbrk: Iranian President Hassan Rouhani: \"We will stick to our promises\" in pending nuclear deal if others do the same. http://t.co/Y0\u2026\n",
        "RT @cnnbrk: Iranian President Hassan Rouhani: \"We will stick to our promises\" in pending nuclear deal if others do the same. http://t.co/Y0\u2026\n",
        "RT @cnnbrk: Iranian President Hassan Rouhani: \"We will stick to our promises\" in pending nuclear deal if others do the same. http://t.co/Y0\u2026\n",
        "RT @cnni: Iranian President: We will stick to our promises on nuclear deal: http://t.co/ZOEo9TVcZA #IranDeal http://t.co/rSL7wX2Zge\n",
        "RT @cnni: BREAKING: Iranian President Hassan Rouhani vows: \"We will stick to our promises\" made in nuclear deal, adding \"we do not lie.\"\n",
        "RT @cnni: BREAKING: Iranian President Hassan Rouhani vows: \"We will stick to our promises\" made in nuclear deal, adding \"we do not lie.\"\n",
        "RT @cnni: BREAKING: Iranian President Hassan Rouhani vows: \"We will stick to our promises\" made in nuclear deal, adding \"we do not lie.\"\n",
        "RT @cnni: BREAKING: Iranian President Hassan Rouhani vows: \"We will stick to our promises\" made in nuclear deal, adding \"we do not lie.\"\n",
        "RT @cnni: BREAKING: Iranian President Hassan Rouhani vows: \"We will stick to our promises\" made in nuclear deal, adding \"we do not lie.\"\n",
        "RT @BBCBreaking: \"The world has acknowledged Iran is pursuing its peaceful objectives,\" President Rouhani says of #IranTalks deal http://t.\u2026\n",
        "RT @BBCBreaking: \"The world has acknowledged Iran is pursuing its peaceful objectives,\" President Rouhani says of #IranTalks deal http://t.\u2026\n",
        "RT @BBCBreaking: \"The world has acknowledged Iran is pursuing its peaceful objectives,\" President Rouhani says of #IranTalks deal http://t.\u2026\n",
        "RT @BBCBreaking: \"The world has acknowledged Iran is pursuing its peaceful objectives,\" President Rouhani says of #IranTalks deal http://t.\u2026\n",
        "RT @AJEnglish: Obama hails 'historic' Iran nuclear deal http://t.co/maXSjG3AQB\n",
        "RT @AJEnglish: Obama hails 'historic' Iran nuclear deal http://t.co/maXSjG3AQB\n",
        "RT @OutFrontCNN: What's in the Iran nuclear deal? 7 key points http://t.co/mfO3JpXACD @CNN #IranDeal http://t.co/dDJXbgUzc5\n",
        "RT @OutFrontCNN: What's in the Iran nuclear deal? 7 key points http://t.co/mfO3JpXACD @CNN #IranDeal http://t.co/dDJXbgUzc5\n",
        "RT @RichardOHornos: \u25b6\ufe0f@BarackObama says the #IranDeal is a \"good deal\" \ud83d\udc49http://t.co/eIuWwGuX7X http://t.co/tkYP7XgNpx | @CNNPolitics #Thank\u2026\n",
        "RT @CNNPolitics: What's in the Iran nuclear deal? Here are 7 key points: http://t.co/Q64yk0mQBw (via @ericbradner)\n",
        "RT @CNNMoney: What the Iran nuclear deal has done to oil prices http://t.co/p71LMKYOay By @MattMEgan5 @byHeatherLong http://t.co/X8apBAWYQF\n",
        "RT @ReutersBiz: Oil falls nearly 4 percent after tentative nuclear deal for Iran http://t.co/Ji26LEnjJt\n",
        "RT @ReutersBiz: Oil falls nearly 4 percent after tentative nuclear deal for Iran http://t.co/Ji26LEnjJt\n",
        "RT @ReutersOpinion: It's a good deal: How both sides can successfully sell the Iran nuclear agreement back home: http://t.co/mF2yxXVXUB htt\u2026\n",
        "RT @ReutersOpinion: It's a good deal: How both sides can successfully sell the Iran nuclear agreement back home: http://t.co/mF2yxXVXUB htt\u2026\n",
        "RT @ReutersOpinion: It's a good deal: How both sides can successfully sell the Iran nuclear agreement back home: http://t.co/mF2yxXVXUB htt\u2026\n",
        "A Major Step Toward a Nuclear Deal http://t.co/HLl9kGpce0 via @YahooNews  @WOC11\n",
        "@Cnnbrk @Foxnews Iran And World Powers Agree On Framework For Nuclear Deal - Huffington Post http://t.co/myppk3VfJu @Reuters @AP #Iran\n",
        "RT @ReutersIran: Billions up for grabs if nuclear deal opens Iran economy http://t.co/Wlpqf2OEVJ\n",
        "Iranians celebrate nuclear deal http://t.co/ZMSXVg6qZ4 via @Reuters; The Iran team were most capable negotiators-hope they are the moderates\n",
        "RT @anniefofani: Oil falls nearly 4 percent after tentative nuclear deal for #Iran http://t.co/gjpSS1paMf via @Reuters\n",
        "RT @BBCBreaking: #IranTalks brought \"historic understanding\" that should stop Iran obtaining nuclear weapon, US President Obama says http:/\u2026\n",
        "@HerbertStehberg @Netanyahu tells Obama Iran deal 'threat to Israel's survival': spokesman http://t.co/F6HeNl6TpV via @YahooNews\n",
        "RT @cnnbrk: Iran nuclear framework is a grave danger to the world, Netanyahu says. http://t.co/Y0TcER84kW\n",
        "RT @cnni: The U.S. and five other powers have reached a nuclear deal with #Iran\u2026 but what\u2019s included in the landmark agreement? http://t.co\u2026\n",
        "RT @cnni: The U.S. and five other powers have reached a nuclear deal with #Iran\u2026 but what\u2019s included in the landmark agreement? http://t.co\u2026\n",
        "RT @FeelFreetuRT: Netanyahu tells Obama Iran deal 'threat to Israel's survival': spokesman http://t.co/qYQdd6bqtg via @YahooNews\n",
        "RT @sandykjack: Netanyahu tells Obama Iran deal 'threat to Israel's survival': spokesman http://t.co/YEZN6WPwyK via @YahooNews\n",
        "Why Obama desperately wants an Iran deal:  http://t.co/HAIod1ODmy (Via @CNN)\n",
        "Obama ties legacy to Iran deal: President Barack Obama on Thursday effectively placed his presidenti... http://t.co/QPu8awG4It (By @CNN)\n",
        "On @npr, @nytimes reporter refers to @gop Republicans as \"American hardliners\" with regard to Iran nuclear deal. That's not biased at all.\n",
        "RT @BBCBreaking: \"We can cooperate with the world,\" President Rouhani says; if others honour #IranTalks pledges, \"we will as well\" http://t\u2026\n",
        "RT @BBCBreaking: \"We can cooperate with the world,\" President Rouhani says; if others honour #IranTalks pledges, \"we will as well\" http://t\u2026\n",
        "RT @CNNPolitics: .@SenTomCotton: Striking Iranian nuclear facilities better than #IranDeal http://t.co/ZNcXnNUI0R #TheLead http://t.co/aEeJ\u2026\n",
        "RT @cnni: BREAKING: Netanyahu: Proposed deal on Iran's nuclear program would pose \"grave danger\" to world, threaten Israel's existence.\n",
        "RT @BBCBreaking: Iran's right to enrich uranium \"is not a threat\" to any other nation, President Rouhani says http://t.co/8GcN1rdOgk #IranT\u2026\n",
        "RT @BBCBreaking: Iran's right to enrich uranium \"is not a threat\" to any other nation, President Rouhani says http://t.co/8GcN1rdOgk #IranT\u2026\n",
        "RT @cnni: From social media to the streets, Iranians erupt with joy after nuclear deal: http://t.co/ekIHeLHaOd http://t.co/nmm4sdIhE0\n",
        "Cluster # 3-----------------------\n",
        "\n",
        "Total items # 10-----------------------\n",
        "\n",
        "\n",
        "-0.357*\"days\" + -0.343*\"man\" + -0.311*\"water\" + -0.309*\"sea\" + -0.309*\"rescued\" + -0.282*\"fish\" + -0.282*\"catching\" + -0.282*\"survived\" + -0.260*\"hands\" + -0.256*\"drinking\"\n",
        "\n",
        "RT @cnnbrk: Man rescued after 66 days at sea. He survived by catching fish with his hands, drinking rain water. http://t.co/4kLVnI9ff8\n",
        "RT @cnnbrk: Man rescued after 66 days at sea. He survived by catching fish with his hands, drinking rain water. http://t.co/4kLVnI9ff8\n",
        "RT @cnnbrk: Man rescued after 66 days at sea. He survived by catching fish with his hands, drinking rain water. http://t.co/4kLVnI9ff8\n",
        "RT @cnnbrk: Man rescued after 66 days at sea. He survived by catching fish with his hands, drinking rain water. http://t.co/4kLVnI9ff8\n",
        "RT @cnni: Man rescued after 66 days at sea. He survived by catching fish with his hands, drinking rain water. http://t.co/kLrLOnrE59\n",
        "RT @cnnbrk: Man rescued after 66 days at sea. He survived by catching fish with his hands, drinking rain water. http://t.co/4kLVnI9ff8\n",
        "RT @cnnbrk: Man rescued after 66 days at sea. He survived by catching fish with his hands, drinking rain water. http://t.co/4kLVnI9ff8\n",
        "RT @Zak_Bagans: Did he make peanut butter &amp; jellyfish sandwiches? \u201c@cnnbrk: Man rescued after 66 days at sea. He survived by catching fish \u2026\n",
        "RT @CNNWire: Sailor rescued after 66 days at sea.\n",
        "RT @TheLeadCNN: Coast Guard believes man rescued was lost at sea for 66 days -- \n",
        "Cluster # 1-----------------------\n",
        "\n",
        "Total items # 32-----------------------\n",
        "\n",
        "\n",
        "-0.424*\"black\" + -0.418*\"box\" + -0.410*\"confirms\" + -0.386*\"flight\" + -0.338*\"investigators\" + -0.300*\"acted\" + -0.300*\"deliberately\" + -0.061*\"increased\" + -0.061*\"germanwings\" + -0.061*\"speed\"\n",
        "\n",
        "RT @BBCBreaking: 2nd black box on #Germanwings flight confirms \"co-pilot acted deliberately\", say investigators http://t.co/WY3m3w5MVS http\u2026\n",
        "RT @BBCBreaking: 2nd black box on #Germanwings flight confirms \"co-pilot acted deliberately\", say investigators http://t.co/WY3m3w5MVS http\u2026\n",
        "RT @BBCBreaking: 2nd black box on #Germanwings flight confirms \"co-pilot acted deliberately\", say investigators http://t.co/WY3m3w5MVS http\u2026\n",
        "RT @BBCBreaking: 2nd black box on #Germanwings flight confirms \"co-pilot acted deliberately\", say investigators http://t.co/WY3m3w5MVS http\u2026\n",
        "RT @BBCBreaking: 2nd black box on #Germanwings flight confirms \"co-pilot acted deliberately\", say investigators http://t.co/WY3m3w5MVS http\u2026\n",
        "RT @BBCBreaking: 2nd black box on #Germanwings flight confirms \"co-pilot acted deliberately\", say investigators http://t.co/WY3m3w5MVS http\u2026\n",
        "RT @BBCBreaking: 2nd black box on #Germanwings flight confirms \"co-pilot acted deliberately\", say investigators http://t.co/WY3m3w5MVS http\u2026\n",
        "RT @BBCBreaking: 2nd black box on #Germanwings flight confirms \"co-pilot acted deliberately\", say investigators http://t.co/WY3m3w5MVS http\u2026\n",
        "RT @BBCBreaking: 2nd black box on #Germanwings flight confirms \"co-pilot acted deliberately\", say investigators http://t.co/WY3m3w5MVS http\u2026\n",
        "RT @BBCBreaking: 2nd black box on #Germanwings flight confirms \"co-pilot acted deliberately\", say investigators http://t.co/WY3m3w5MVS http\u2026\n",
        "RT @BBCBreaking: 2nd black box on #Germanwings flight confirms \"co-pilot acted deliberately\", say investigators http://t.co/WY3m3w5MVS http\u2026\n",
        "RT @BBCBreaking: 2nd black box on #Germanwings flight confirms \"co-pilot acted deliberately\", say investigators http://t.co/WY3m3w5MVS http\u2026\n",
        "RT @BBCBreaking: 2nd black box on #Germanwings flight confirms \"co-pilot acted deliberately\", say investigators http://t.co/WY3m3w5MVS http\u2026\n",
        "RT @BBCBreaking: 2nd black box on #Germanwings flight confirms \"co-pilot acted deliberately\", say investigators http://t.co/WY3m3w5MVS http\u2026\n",
        "RT @BBCBreaking: 2nd black box on #Germanwings flight confirms \"co-pilot acted deliberately\", say investigators http://t.co/WY3m3w5MVS http\u2026\n",
        "RT @BBCBreaking: 2nd black box on #Germanwings flight confirms \"co-pilot acted deliberately\", say investigators http://t.co/WY3m3w5MVS http\u2026\n",
        "RT @BBCBreaking: #Germanwings co-pilot \"increased the plane's speed,\" 2nd black box confirms http://t.co/MZkxtwjEpf http://t.co/F8gMUv5CCV\n",
        "RT @BBCBreaking: #Germanwings co-pilot \"increased the plane's speed,\" 2nd black box confirms http://t.co/MZkxtwjEpf http://t.co/F8gMUv5CCV\n",
        "RT @BBCBreaking: #Germanwings co-pilot \"increased the plane's speed,\" 2nd black box confirms http://t.co/MZkxtwjEpf http://t.co/F8gMUv5CCV\n",
        "RT @BBCBreaking: #Germanwings co-pilot \"increased the plane's speed,\" 2nd black box confirms http://t.co/MZkxtwjEpf http://t.co/F8gMUv5CCV\n",
        "RT @BBCBreaking: #Germanwings co-pilot \"increased the plane's speed,\" 2nd black box confirms http://t.co/MZkxtwjEpf http://t.co/F8gMUv5CCV\n",
        "RT @BBCBreaking: #Germanwings co-pilot \"increased the plane's speed,\" 2nd black box confirms http://t.co/MZkxtwjEpf http://t.co/F8gMUv5CCV\n",
        "RT @CNNJason: Pictures of 2nd black box just found ... The flight data recorder of #Germanwings http://t.co/dxl1oqmISF\n",
        "RT @BBCBreaking: #Germanwings co-pilot changed settings to take plane's altitude to 100 feet (30 metres), 2nd black box confirms http://t.c\u2026\n",
        "RT @BBCBreaking: #Germanwings co-pilot changed settings to take plane's altitude to 100 feet (30 metres), 2nd black box confirms http://t.c\u2026\n",
        "RT @BBCBreaking: #Germanwings co-pilot changed settings to take plane's altitude to 100 feet (30 metres), 2nd black box confirms http://t.c\u2026\n",
        "RT @cnnbrk: Germanwings Flight 9525 flight data recorder shows co-pilot purposely sped up plane's descent, investigators say. http://t.co/m\u2026\n",
        "RT @cnnbrk: Germanwings Flight 9525 flight data recorder shows co-pilot purposely sped up plane's descent, investigators say. http://t.co/m\u2026\n",
        "RT @cnnbrk: Germanwings Flight 9525 flight data recorder shows co-pilot purposely sped up plane's descent, investigators say. http://t.co/m\u2026\n",
        "RT @CNN: Germanwings 'black box' shows co-pilot Andreas Lubitz sped up descent: http://t.co/3QTQSUMBLp http://t.co/PfXK9jk0Sa\n",
        "RT @CNN: Germanwings 'black box' shows co-pilot Andreas Lubitz sped up descent: http://t.co/3QTQSUMBLp http://t.co/PfXK9jk0Sa\n",
        "@CNNSitRoom @cnni 2 black women....\n",
        "Total number of tweets is 0\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys  \n",
      "\n",
      "#reload(sys)  \n",
      "#lisys.setdefaultencoding('utf-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 233
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(tweet_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 149,
       "text": [
        "809"
       ]
      }
     ],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sys.getdefaultencoding()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 200,
       "text": [
        "'utf-8'"
       ]
      }
     ],
     "prompt_number": 200
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "number = 2\n",
      "pdb.set_trace()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(Pdb) p number\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(Pdb) p number\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(Pdb) p len(tweet_list)\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(Pdb) c\n"
       ]
      }
     ],
     "prompt_number": 210
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}